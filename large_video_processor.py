# large_video_processor.py - –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞–ø—Ä—è–º—É—é
import cv2
import os
import time
import json
import argparse
from datetime import datetime
from pathlib import Path
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import threading


class LargeVideoProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –±–æ–ª—å—à–∏—Ö –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self, output_dir='training_data'):
        self.output_dir = output_dir
        self.setup_directories()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_extracted = 0
        self.total_processed_frames = 0
        self.start_time = None

        # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.stats_lock = threading.Lock()

    def setup_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫"""
        dirs = [
            f'{self.output_dir}/images',
            f'{self.output_dir}/annotations',
            f'{self.output_dir}/metadata',
            f'{self.output_dir}/previews'
        ]

        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)

        print(f"üìÅ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –≤ {self.output_dir}")

    def process_large_video(self, video_path, strategy='smart', max_frames=1000,
                            quality_threshold=0.3, parallel_processing=True):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–æ–≥–æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞

        Args:
            video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
            strategy: —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ('uniform', 'smart', 'quality_based')
            max_frames: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤
            quality_threshold: –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            parallel_processing: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        """
        if not os.path.exists(video_path):
            print(f"‚ùå –í–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {video_path}")
            return False

        self.start_time = time.time()
        print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–æ–≥–æ –≤–∏–¥–µ–æ: {video_path}")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ
        video_info = self._analyze_video(video_path)
        if not video_info:
            return False

        print(f"üìä –í–∏–¥–µ–æ: {video_info['duration']:.1f} –º–∏–Ω, "
              f"{video_info['total_frames']} –∫–∞–¥—Ä–æ–≤, "
              f"{video_info['fps']:.1f} FPS")
        print(f"üíæ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {video_info['file_size_gb']:.2f} GB")

        # –í—ã–±–∏—Ä–∞–µ–º –∫–∞–¥—Ä—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        print(f"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {strategy}")
        frame_positions = self._select_frames(video_info, strategy, max_frames)

        print(f"üì∏ –í—ã–±—Ä–∞–Ω–æ {len(frame_positions)} –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
        if parallel_processing and len(frame_positions) > 100:
            success = self._extract_frames_parallel(video_path, frame_positions,
                                                    quality_threshold, video_info)
        else:
            success = self._extract_frames_sequential(video_path, frame_positions,
                                                      quality_threshold, video_info)

        if success:
            self._generate_processing_report(video_path, video_info, len(frame_positions))

        return success

    def _analyze_video(self, video_path):
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞"""
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
                return None

            # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            duration_seconds = total_frames / fps if fps > 0 else 0
            file_size = os.path.getsize(video_path)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
            sample_quality = self._sample_video_quality(cap, total_frames)

            cap.release()

            return {
                'total_frames': total_frames,
                'fps': fps,
                'width': width,
                'height': height,
                'duration': duration_seconds / 60,  # –≤ –º–∏–Ω—É—Ç–∞—Ö
                'file_size_gb': file_size / (1024 ** 3),
                'avg_quality': sample_quality,
                'bitrate_estimate': (file_size * 8) / duration_seconds if duration_seconds > 0 else 0
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ: {e}")
            return None

    def _sample_video_quality(self, cap, total_frames, num_samples=10):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞–∑—Ü–æ–≤"""
        qualities = []

        for i in range(num_samples):
            frame_pos = (total_frames // num_samples) * i
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)

            ret, frame = cap.read()
            if ret:
                # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—Ä–∏–∞—Ü–∏–∏
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                quality = cv2.Laplacian(gray, cv2.CV_64F).var()
                qualities.append(quality)

        return np.mean(qualities) if qualities else 0

    def _select_frames(self, video_info, strategy, max_frames):
        """–í—ã–±–æ—Ä –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        total_frames = video_info['total_frames']

        if strategy == 'uniform':
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            if total_frames <= max_frames:
                return list(range(0, total_frames, max(1, total_frames // max_frames)))
            else:
                step = total_frames // max_frames
                return list(range(0, total_frames, step))[:max_frames]

        elif strategy == 'smart':
            # –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –∏ –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
            return self._smart_frame_selection(video_info, max_frames)

        elif strategy == 'quality_based':
            # –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (–±–æ–ª–µ–µ –∑–∞—Ç—Ä–∞—Ç–Ω–æ)
            return self._quality_based_selection(video_info, max_frames)

        else:
            print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy}, –∏—Å–ø–æ–ª—å–∑—É–µ–º uniform")
            return self._select_frames(video_info, 'uniform', max_frames)

    def _smart_frame_selection(self, video_info, max_frames):
        """–£–º–Ω—ã–π –≤—ã–±–æ—Ä –∫–∞–¥—Ä–æ–≤ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π"""
        total_frames = video_info['total_frames']
        fps = video_info['fps']

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å–µ–≥–º–µ–Ω—Ç–∞–º
        segment_duration = 30  # —Å–µ–∫—É–Ω–¥ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç
        frames_per_segment = int(fps * segment_duration)

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        num_segments = total_frames // frames_per_segment
        frames_per_segment_to_extract = max_frames // max(1, num_segments)

        selected_frames = []

        for segment in range(num_segments):
            segment_start = segment * frames_per_segment
            segment_end = min(segment_start + frames_per_segment, total_frames)

            # –í –∫–∞–∂–¥–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ –±–µ—Ä–µ–º –∫–∞–¥—Ä—ã —Å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
            if frames_per_segment_to_extract > 0:
                step = (segment_end - segment_start) // frames_per_segment_to_extract
                for i in range(frames_per_segment_to_extract):
                    frame_pos = segment_start + (i * step)
                    if frame_pos < total_frames:
                        selected_frames.append(frame_pos)

        return selected_frames[:max_frames]

    def _quality_based_selection(self, video_info, max_frames):
        """–í—ã–±–æ—Ä –∫–∞–¥—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞"""
        # –≠—Ç–æ –±–æ–ª–µ–µ –∑–∞—Ç—Ä–∞—Ç–Ω—ã–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤
        # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        total_frames = video_info['total_frames']
        sample_rate = max(1, total_frames // (max_frames * 3))  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ 3 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –∫–∞–¥—Ä–æ–≤

        candidate_frames = list(range(0, total_frames, sample_rate))
        return candidate_frames[:max_frames]

    def _extract_frames_sequential(self, video_path, frame_positions, quality_threshold, video_info):
        """–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤"""
        print("üì∏ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤...")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return False

        video_name = Path(video_path).stem
        extracted_count = 0

        try:
            for i, frame_pos in enumerate(frame_positions):
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
                ret, frame = cap.read()

                if ret:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–∞
                    if self._check_frame_quality(frame, quality_threshold):
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
                        filename = f"{video_name}_frame_{frame_pos:08d}_{timestamp}.jpg"
                        filepath = os.path.join(self.output_dir, 'images', filename)

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä
                        cv2.imwrite(filepath, frame)

                        # –ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                        detections = self._simple_detection(frame)
                        self._save_frame_annotation(filename, frame_pos, video_path,
                                                    frame.shape, detections)

                        extracted_count += 1

                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                        with self.stats_lock:
                            self.total_extracted += 1
                            self.total_processed_frames += 1

                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                if (i + 1) % 50 == 0:
                    progress = ((i + 1) / len(frame_positions)) * 100
                    elapsed = time.time() - self.start_time
                    eta = (elapsed / (i + 1)) * (len(frame_positions) - i - 1)

                    print(f"   üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% "
                          f"({extracted_count} –∏–∑–≤–ª–µ—á–µ–Ω–æ, "
                          f"ETA: {eta / 60:.1f} –º–∏–Ω)")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            return False
        finally:
            cap.release()

        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {extracted_count} –∫–∞–¥—Ä–æ–≤ –∏–∑ {len(frame_positions)}")
        return True

    def _extract_frames_parallel(self, video_path, frame_positions, quality_threshold, video_info):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤"""
        print("‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤...")

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        num_workers = min(4, os.cpu_count())  # –ù–µ –±–æ–ª–µ–µ 4 –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ
        chunk_size = len(frame_positions) // num_workers

        chunks = []
        for i in range(0, len(frame_positions), chunk_size):
            chunks.append(frame_positions[i:i + chunk_size])

        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º {len(chunks)} –ø–æ—Ç–æ–∫–æ–≤ –ø–æ ~{chunk_size} –∫–∞–¥—Ä–æ–≤")

        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = []

            for chunk_idx, chunk in enumerate(chunks):
                future = executor.submit(
                    self._process_chunk,
                    video_path, chunk, quality_threshold, video_info, chunk_idx
                )
                futures.append(future)

            # –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
            total_extracted = 0
            for future in futures:
                extracted = future.result()
                total_extracted += extracted

        print(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {total_extracted} –∫–∞–¥—Ä–æ–≤")
        return True

    def _process_chunk(self, video_path, frame_positions, quality_threshold, video_info, chunk_idx):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ –∫–∞–¥—Ä–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"‚ùå –ü–æ—Ç–æ–∫ {chunk_idx}: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ")
            return 0

        video_name = Path(video_path).stem
        extracted_count = 0

        try:
            for frame_pos in frame_positions:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
                ret, frame = cap.read()

                if ret and self._check_frame_quality(frame, quality_threshold):
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
                    filename = f"{video_name}_chunk{chunk_idx}_frame_{frame_pos:08d}_{timestamp}.jpg"
                    filepath = os.path.join(self.output_dir, 'images', filename)

                    cv2.imwrite(filepath, frame)

                    # –î–µ—Ç–µ–∫—Ü–∏—è –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è
                    detections = self._simple_detection(frame)
                    self._save_frame_annotation(filename, frame_pos, video_path,
                                                frame.shape, detections)

                    extracted_count += 1

                    # –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    with self.stats_lock:
                        self.total_extracted += 1

        except Exception as e:
            print(f"‚ùå –ü–æ—Ç–æ–∫ {chunk_idx} –æ—à–∏–±–∫–∞: {e}")
        finally:
            cap.release()

        print(f"   ‚úÖ –ü–æ—Ç–æ–∫ {chunk_idx}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {extracted_count} –∫–∞–¥—Ä–æ–≤")
        return extracted_count

    def _check_frame_quality(self, frame, threshold):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–¥—Ä–∞"""
        if threshold <= 0:
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑–∫–æ—Å—Ç—å
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–∞–¥—Ä –Ω–µ —Å–ª–∏—à–∫–æ–º —Ç–µ–º–Ω—ã–π/—Å–≤–µ—Ç–ª—ã–π
        mean_brightness = np.mean(gray)

        return (laplacian_var > threshold * 1000 and
                20 < mean_brightness < 235)

    def _simple_detection(self, frame):
        """–ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Ö–ª–µ–±–∞"""
        detections = []

        # HSV –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ö–ª–µ–±–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        # –ú–∞—Å–∫–∞ –¥–ª—è —Ö–ª–µ–±–∞
        lower = np.array([10, 30, 30])
        upper = np.array([40, 255, 255])
        mask = cv2.inRange(hsv, lower, upper)

        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

        # –ö–æ–Ω—Ç—É—Ä—ã
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for i, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            if 1000 < area < 80000:  # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É
                x, y, w, h = cv2.boundingRect(contour)

                detections.append({
                    'id': i,
                    'bbox': [x, y, x + w, y + h],
                    'center': [x + w // 2, y + h // 2],
                    'area': area,
                    'confidence': 0.8,
                    'class_name': 'bread'
                })

        return detections

    def _save_frame_annotation(self, filename, frame_pos, video_path, frame_shape, detections):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∫–∞–¥—Ä–∞"""
        annotation = {
            'filename': filename,
            'source_video': video_path,
            'frame_position': frame_pos,
            'timestamp': datetime.now().isoformat(),
            'resolution': {
                'width': frame_shape[1],
                'height': frame_shape[0],
                'channels': frame_shape[2]
            },
            'detections': detections,
            'detection_count': len(detections),
            'extraction_method': 'large_video_processor'
        }

        annotation_file = os.path.join(
            self.output_dir, 'annotations',
            filename.replace('.jpg', '.json')
        )

        with open(annotation_file, 'w', encoding='utf-8') as f:
            json.dump(annotation, f, indent=2, ensure_ascii=False)

    def _generate_processing_report(self, video_path, video_info, processed_frames):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        total_time = time.time() - self.start_time

        report = {
            'processing_date': datetime.now().isoformat(),
            'source_video': {
                'path': video_path,
                'size_gb': video_info['file_size_gb'],
                'duration_minutes': video_info['duration'],
                'total_frames': video_info['total_frames'],
                'fps': video_info['fps']
            },
            'processing_stats': {
                'processed_frame_positions': processed_frames,
                'extracted_frames': self.total_extracted,
                'success_rate': self.total_extracted / processed_frames if processed_frames > 0 else 0,
                'processing_time_seconds': total_time,
                'frames_per_second': self.total_extracted / total_time if total_time > 0 else 0
            },
            'output_directory': self.output_dir
        }

        report_file = os.path.join(self.output_dir, 'processing_report.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
        print("\nüìä –û–¢–ß–ï–¢ –û–ë –û–ë–†–ê–ë–û–¢–ö–ï –í–ò–î–ï–û")
        print("=" * 50)
        print(f"üé¨ –í–∏–¥–µ–æ: {Path(video_path).name}")
        print(f"üíæ –†–∞–∑–º–µ—Ä: {video_info['file_size_gb']:.2f} GB")
        print(f"‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {video_info['duration']:.1f} –º–∏–Ω")
        print(f"üì∏ –ò–∑–≤–ª–µ—á–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {self.total_extracted}")
        print(f"‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time / 60:.1f} –º–∏–Ω")
        print(f"üöÄ –°–∫–æ—Ä–æ—Å—Ç—å: {self.total_extracted / total_time:.1f} –∫–∞–¥—Ä–æ–≤/—Å–µ–∫")
        print(f"üìÑ –û—Ç—á–µ—Ç: {report_file}")
        print("=" * 50)

    def process_multiple_videos(self, videos_dir, **kwargs):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–æ–ª—å—à–∏—Ö –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤"""
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']

        video_files = []
        for ext in video_extensions:
            video_files.extend(Path(videos_dir).glob(f'*{ext}'))

        if not video_files:
            print(f"‚ùå –í–∏–¥–µ–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {videos_dir}")
            return

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –≤ –∫–æ–Ω—Ü–µ)
        video_files.sort(key=lambda x: x.stat().st_size)

        print(f"üé¨ –ù–∞–π–¥–µ–Ω–æ {len(video_files)} –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        total_processed = 0
        total_start_time = time.time()

        for i, video_path in enumerate(video_files, 1):
            size_gb = video_path.stat().st_size / (1024 ** 3)
            print(f"\nüìπ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {i}/{len(video_files)}: {video_path.name} ({size_gb:.2f} GB)")

            if self.process_large_video(str(video_path), **kwargs):
                total_processed += 1

        total_time = time.time() - total_start_time

        print(f"\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed}/{len(video_files)} –≤–∏–¥–µ–æ")
        print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time / 3600:.1f} —á–∞—Å–æ–≤")
        print(f"üì∏ –í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {self.total_extracted} –∫–∞–¥—Ä–æ–≤")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('--video', help='–ü—É—Ç—å –∫ –æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É')
    parser.add_argument('--videos-dir', help='–ü–∞–ø–∫–∞ —Å –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--output', default='training_data', help='–ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--strategy', choices=['uniform', 'smart', 'quality_based'],
                        default='smart', help='–°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤')
    parser.add_argument('--max-frames', type=int, default=1000,
                        help='–ú–∞–∫—Å–∏–º—É–º –∫–∞–¥—Ä–æ–≤ –Ω–∞ –≤–∏–¥–µ–æ')
    parser.add_argument('--quality', type=float, default=0.3,
                        help='–ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ (0.0-1.0)')
    parser.add_argument('--parallel', action='store_true', default=True,
                        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É')
    parser.add_argument('--no-parallel', action='store_true',
                        help='–û—Ç–∫–ª—é—á–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É')

    args = parser.parse_args()

    if args.no_parallel:
        args.parallel = False

    print("üé¨ –û–ë–†–ê–ë–û–¢–ß–ò–ö –ë–û–õ–¨–®–ò–• –í–ò–î–ï–û –§–ê–ô–õ–û–í")
    print("=" * 60)
    print(f"üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {args.output}")
    print(f"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {args.strategy}")
    print(f"üì∏ –ú–∞–∫—Å –∫–∞–¥—Ä–æ–≤ –Ω–∞ –≤–∏–¥–µ–æ: {args.max_frames}")
    print(f"‚ú® –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞: {args.quality}")
    print(f"‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {'–î–∞' if args.parallel else '–ù–µ—Ç'}")

    try:
        processor = LargeVideoProcessor(args.output)

        if args.video:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            print(f"\nüé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {args.video}")
            processor.process_large_video(
                args.video,
                strategy=args.strategy,
                max_frames=args.max_frames,
                quality_threshold=args.quality,
                parallel_processing=args.parallel
            )

        elif args.videos_dir:
            # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            print(f"\nüìÅ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: {args.videos_dir}")
            processor.process_multiple_videos(
                args.videos_dir,
                strategy=args.strategy,
                max_frames=args.max_frames,
                quality_threshold=args.quality,
                parallel_processing=args.parallel
            )

        else:
            print("‚ùå –£–∫–∞–∂–∏—Ç–µ --video –∏–ª–∏ --videos-dir")
            print("\n–ü—Ä–∏–º–µ—Ä—ã:")
            print("  python large_video_processor.py --video /path/to/big_video.mp4")
            print("  python large_video_processor.py --videos-dir /path/to/videos/")
            print("  python large_video_processor.py --videos-dir ./videos --strategy smart --max-frames 500")

    except KeyboardInterrupt:
        print("\nüõë –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()