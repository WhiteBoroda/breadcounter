# coral_detector.py - Ð”ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ð´Ð»Ñ Coral TPU
import numpy as np
import cv2
from pycoral.utils import edgetpu
from pycoral.utils import dataset
from pycoral.adapters import common
from pycoral.adapters import detect
import tflite_runtime.interpreter as tflite
from PIL import Image
import time


class CoralBreadDetector:
    """Ð”ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ñ…Ð»ÐµÐ±Ð° Ð½Ð° Coral TPU"""

    def __init__(self, model_path='bread_detector_edgetpu.tflite', labels_path='labels.txt'):
        print("ðŸ§  Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Coral TPU Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€Ð°...")

        try:
            # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Coral TPU
            self.interpreter = edgetpu.make_interpreter(model_path)
            self.interpreter.allocate_tensors()
            print("âœ… Coral TPU Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Coral TPU: {e}")
            raise

        # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼ÐµÑ‚Ð¾Ðº
        try:
            self.labels = dataset.read_label_file(labels_path) if labels_path else {}
            print(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(self.labels)} ÐºÐ»Ð°ÑÑÐ¾Ð²")
        except:
            print("âš ï¸  Ð¤Ð°Ð¹Ð» Ð¼ÐµÑ‚Ð¾Ðº Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÐºÐ»Ð°ÑÑÑ‹")
            self.labels = {0: 'background', 1: 'bread', 2: 'circle', 3: 'square', 4: 'triangle'}

        # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        self.input_size = common.input_size(self.interpreter)

        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        self.inference_times = []

        print(f"ðŸŽ¯ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð³Ð¾Ñ‚Ð¾Ð²Ð°, Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð²Ñ…Ð¾Ð´Ð°: {self.input_size}")

    def detect(self, frame):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð½Ð° ÐºÐ°Ð´Ñ€Ðµ"""
        start_time = time.time()

        # ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(rgb_frame)
        resized_image = pil_image.resize(self.input_size, Image.LANCZOS)

        # Ð˜Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ð½Ð° Coral TPU
        common.set_input(self.interpreter, resized_image)
        self.interpreter.invoke()

        # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        objs = detect.get_objects(self.interpreter, threshold=0.4)

        # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ Ðº Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ñ€Ð°Ð·Ð¼ÐµÑ€Ñƒ
        scale_x = frame.shape[1] / self.input_size[0]
        scale_y = frame.shape[0] / self.input_size[1]

        detections = []
        for obj in objs:
            bbox = obj.bbox.scale(scale_x, scale_y)

            detection = {
                'class_id': obj.id,
                'class_name': self.labels.get(obj.id, 'unknown'),
                'confidence': obj.score,
                'bbox': (bbox.xmin, bbox.ymin, bbox.xmax, bbox.ymax),
                'center': ((bbox.xmin + bbox.xmax) / 2, (bbox.ymin + bbox.ymax) / 2)
            }
            detections.append(detection)

        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        inference_time = time.time() - start_time
        self.inference_times.append(inference_time)
        if len(self.inference_times) > 100:
            self.inference_times.pop(0)

        return detections

    def get_performance_stats(self):
        """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        if not self.inference_times:
            return {'avg_time': 0, 'fps': 0, 'device': 'Coral TPU'}

        avg_time = np.mean(self.inference_times)
        fps = 1.0 / avg_time if avg_time > 0 else 0

        return {
            'avg_inference_time': avg_time,
            'fps': fps,
            'min_time': np.min(self.inference_times),
            'max_time': np.max(self.inference_times),
            'device': 'Coral TPU'
        }