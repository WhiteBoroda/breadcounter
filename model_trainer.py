# model_trainer.py - –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ö–ª–µ–±–∞
import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
import json
import os
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from pathlib import Path


class BreadDetectionTrainer:
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ö–ª–µ–±–∞ –¥–ª—è Coral TPU"""

    def __init__(self, data_dir, model_name='bread_detector'):
        self.data_dir = data_dir
        self.model_name = model_name
        self.classes = ['background', 'bread', 'circle', 'square', 'triangle', 'diamond', 'star', 'defective_bread']
        self.num_classes = len(self.classes)
        self.input_size = (320, 320)  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

        print(f"üéì –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞ –º–æ–¥–µ–ª–∏")
        print(f"üìÅ –î–∞–Ω–Ω—ã–µ: {data_dir}")
        print(f"üè∑Ô∏è  –ö–ª–∞—Å—Å—ã: {', '.join(self.classes[1:])}")  # –ë–µ–∑ background

    def prepare_dataset(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")

        images_dir = os.path.join(self.data_dir, 'images')
        annotations_dir = os.path.join(self.data_dir, 'annotations')

        if not os.path.exists(images_dir) or not os.path.exists(annotations_dir):
            raise FileNotFoundError("–ü–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö.")

        images = []
        labels = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        annotation_files = [f for f in os.listdir(annotations_dir) if f.endswith('.json')]

        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(annotation_files)}")

        for ann_file in annotation_files:
            ann_path = os.path.join(annotations_dir, ann_file)
            img_file = ann_file.replace('.json', '.jpg')
            img_path = os.path.join(images_dir, img_file)

            if not os.path.exists(img_path):
                print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {img_file} - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                continue

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = cv2.imread(img_path)
            if image is None:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {img_file}")
                continue

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            try:
                with open(ann_path, 'r', encoding='utf-8') as f:
                    ann_data = json.load(f)

                annotations = ann_data.get('annotations', [])
                if not annotations:
                    print(f"‚ö†Ô∏è  –ù–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ {ann_file}")
                    continue

                images.append(image)
                labels.append(annotations)

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π {ann_file}: {e}")
                continue

        if len(images) < 5:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ú–∏–Ω–∏–º—É–º 5.")

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏")

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val
        train_images, val_images, train_labels, val_labels = train_test_split(
            images, labels, test_size=0.2, random_state=42
        )

        print(f"üéì –û–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä: {len(train_images)}")
        print(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä: {len(val_images)}")

        return (train_images, train_labels), (val_images, val_labels)

    def create_model(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ MobileNetV2"""
        print("üèóÔ∏è  –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

        # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å MobileNetV2 (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è Coral TPU)
        base_model = tf.keras.applications.MobileNetV2(
            input_shape=(self.input_size[0], self.input_size[1], 3),
            include_top=False,
            weights='imagenet'
        )

        # –ó–∞–º–æ—Ä–æ–∑–∏–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è transfer learning
        base_model.trainable = False

        # –î–æ–±–∞–≤–ª—è–µ–º –≥–æ–ª–æ–≤—É –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(self.num_classes, activation='softmax')
        ])

        print("üìã –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
        model.summary()

        return model

    def train_model(self, epochs=50, batch_size=16):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        print("üéì –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        try:
            (train_images, train_labels), (val_images, val_labels) = self.prepare_dataset()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = self.create_model()

        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        print("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")
        train_gen = self._create_data_generator(train_images, train_labels, batch_size, augment=True)
        val_gen = self._create_data_generator(val_images, val_labels, batch_size, augment=False)

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
        steps_per_epoch = max(1, len(train_images) // batch_size)
        validation_steps = max(1, len(val_images) // batch_size)

        print(f"üìä –®–∞–≥–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É: {steps_per_epoch}")
        print(f"üìä –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤: {validation_steps}")

        # Callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                patience=15,
                restore_best_weights=True,
                monitor='val_accuracy'
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                factor=0.5,
                patience=8,
                monitor='val_accuracy'
            ),
            tf.keras.callbacks.ModelCheckpoint(
                f'{self.model_name}_best.h5',
                save_best_only=True,
                monitor='val_accuracy',
                verbose=1
            )
        ]

        # –û–±—É—á–µ–Ω–∏–µ
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {epochs} —ç–ø–æ—Ö...")
        history = model.fit(
            train_gen,
            steps_per_epoch=steps_per_epoch,
            validation_data=val_gen,
            validation_steps=validation_steps,
            epochs=epochs,
            callbacks=callbacks,
            verbose=1
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        final_model_path = f'{self.model_name}_final.h5'
        model.save(final_model_path)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
        self._save_training_history(history)

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        self._plot_training_history(history)

        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        return model, history

    def _create_data_generator(self, images, labels, batch_size, augment=False):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""

        def generator():
            while True:
                # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                indices = np.random.permutation(len(images))

                for i in range(0, len(indices), batch_size):
                    batch_indices = indices[i:i + batch_size]
                    batch_images = []
                    batch_labels = []

                    for idx in batch_indices:
                        if idx >= len(images):
                            continue

                        image = images[idx]
                        anns = labels[idx]

                        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        processed_image = self._preprocess_image(image, augment)

                        # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –±–µ—Ä–µ–º –∫–ª–∞—Å—Å –ø–µ—Ä–≤–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                        # –í –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã
                        if anns:
                            class_name = anns[0]['class_name']
                            label = self._get_class_index(class_name)
                        else:
                            label = 0  # background

                        batch_images.append(processed_image)
                        batch_labels.append(label)

                    if batch_images:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –±–∞—Ç—á –Ω–µ –ø—É—Å—Ç–æ–π
                        yield np.array(batch_images), np.array(batch_labels)

        return generator()

    def _preprocess_image(self, image, augment=False):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
        resized = cv2.resize(image, self.input_size)

        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        if augment:
            resized = self._augment_image(resized)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        normalized = resized.astype(np.float32) / 255.0

        return normalized

    def _augment_image(self, image):
        """–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –°–ª—É—á–∞–π–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç
        if np.random.random() > 0.5:
            angle = np.random.uniform(-10, 10)
            h, w = image.shape[:2]
            center = (w // 2, h // 2)
            matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            image = cv2.warpAffine(image, matrix, (w, h))

        # –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏
        if np.random.random() > 0.5:
            brightness = np.random.uniform(0.8, 1.2)
            image = np.clip(image * brightness, 0, 255).astype(np.uint8)

        # –°–ª—É—á–∞–π–Ω–æ–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
        if np.random.random() > 0.5:
            image = cv2.flip(image, 1)

        return image

    def _get_class_index(self, class_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∫–ª–∞—Å—Å–∞"""
        try:
            return self.classes.index(class_name)
        except ValueError:
            print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å: {class_name}, –∏—Å–ø–æ–ª—å–∑—É–µ–º background")
            return 0

    def _save_training_history(self, history):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        history_data = {
            'loss': history.history['loss'],
            'accuracy': history.history['accuracy'],
            'val_loss': history.history['val_loss'],
            'val_accuracy': history.history['val_accuracy'],
            'epochs': len(history.history['loss'])
        }

        history_path = f'{self.model_name}_history.json'
        with open(history_path, 'w') as f:
            json.dump(history_data, f, indent=2)

        print(f"üìà –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {history_path}")

    def _plot_training_history(self, history):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            plt.figure(figsize=(12, 4))

            # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
            plt.subplot(1, 2, 1)
            plt.plot(history.history['accuracy'], label='Train Accuracy')
            plt.plot(history.history['val_accuracy'], label='Val Accuracy')
            plt.title('Model Accuracy')
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.legend()

            # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
            plt.subplot(1, 2, 2)
            plt.plot(history.history['loss'], label='Train Loss')
            plt.plot(history.history['val_loss'], label='Val Loss')
            plt.title('Model Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.legend()

            plt.tight_layout()

            plot_path = f'{self.model_name}_training_plots.png'
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()

            print(f"üìä –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {plot_path}")

        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏: {e}")

    def convert_to_tflite(self, model_path):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TensorFlow Lite"""
        print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TensorFlow Lite...")

        if not os.path.exists(model_path):
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            return None

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model = tf.keras.models.load_model(model_path)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ TF Lite
            converter = tf.lite.TFLiteConverter.from_keras_model(model)

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            converter.optimizations = [tf.lite.Optimize.DEFAULT]

            # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è Edge TPU
            converter.representative_dataset = self._representative_dataset
            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
            converter.inference_input_type = tf.uint8
            converter.inference_output_type = tf.uint8

            print("‚öôÔ∏è  –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é INT8...")
            tflite_model = converter.convert()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º TF Lite –º–æ–¥–µ–ª—å
            tflite_path = f'{self.model_name}.tflite'
            with open(tflite_path, 'wb') as f:
                f.write(tflite_model)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–∑–º–µ—Ä–µ
            model_size_mb = len(tflite_model) / (1024 * 1024)
            print(f"üíæ TF Lite –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {tflite_path}")
            print(f"üìè –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: {model_size_mb:.2f} MB")

            return tflite_path

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
            return None

    def _representative_dataset(self):
        """–ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏"""
        try:
            (train_images, _), _ = self.prepare_dataset()

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ 100 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
            sample_count = min(100, len(train_images))

            for i in range(sample_count):
                image = self._preprocess_image(train_images[i], augment=False)
                yield [np.expand_dims(image, axis=0)]

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ representative dataset: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ fallback
            for _ in range(10):
                yield [np.random.random((1, self.input_size[0], self.input_size[1], 3)).astype(np.float32)]

    def compile_for_edge_tpu(self, tflite_path):
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è Edge TPU"""
        print("üß† –ö–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è Edge TPU...")

        if not os.path.exists(tflite_path):
            print(f"‚ùå TF Lite –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {tflite_path}")
            return None

        output_path = f'{self.model_name}_edgetpu.tflite'

        try:
            import subprocess

            # –ö–æ–º–∞–Ω–¥–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
            cmd = [
                'edgetpu_compiler',
                tflite_path,
                '-o', os.path.dirname(output_path) or '.'
            ]

            print(f"üîß –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)

            if result.returncode == 0:
                print(f"‚úÖ Edge TPU –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {output_path}")
                print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏:")
                print(result.stdout)
                return output_path
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ Edge TPU:")
                print(result.stderr)
                return None

        except subprocess.TimeoutExpired:
            print("‚ùå –¢–∞–π–º–∞—É—Ç –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ Edge TPU")
            return None
        except FileNotFoundError:
            print("‚ùå Edge TPU Compiler –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: sudo apt install edgetpu-compiler")
            print("   –∏–ª–∏ —Å–∫–∞—á–∞–π—Ç–µ —Å https://coral.ai/software/#edgetpu-compiler")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏: {e}")
            return None

    def create_labels_file(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –º–µ—Ç–æ–∫ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        labels_path = 'labels.txt'
        with open(labels_path, 'w', encoding='utf-8') as f:
            for i, class_name in enumerate(self.classes):
                f.write(f"{i} {class_name}\n")

        print(f"üè∑Ô∏è  –§–∞–π–ª –º–µ—Ç–æ–∫ —Å–æ–∑–¥–∞–Ω: {labels_path}")
        return labels_path


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    import argparse

    parser = argparse.ArgumentParser(description='–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ö–ª–µ–±–∞')
    parser.add_argument('--data', default='training_data', help='–ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('--epochs', type=int, default=50, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö')
    parser.add_argument('--batch-size', type=int, default=16, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')

    args = parser.parse_args()

    print("üß† –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–ï–¢–ï–ö–¶–ò–ò –•–õ–ï–ë–ê")
    print("=" * 50)

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if not os.path.exists(args.data):
            print(f"‚ùå –ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {args.data}")
            print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö: python training_pipeline.py")
            return

        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        trainer = BreadDetectionTrainer(args.data)

        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model, history = trainer.train_model(epochs=args.epochs, batch_size=args.batch_size)

        if model and history:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –º–µ—Ç–æ–∫
            trainer.create_labels_file()

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ TF Lite
            print("\nüîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
            tflite_path = trainer.convert_to_tflite('bread_detector_final.h5')

            if tflite_path:
                # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –¥–ª—è Edge TPU
                print("\nüß† –ö–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è Coral TPU...")
                edge_tpu_path = trainer.compile_for_edge_tpu(tflite_path)

                print(f"\nüéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
                print("=" * 50)
                print(f"üìÑ –û–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å: bread_detector_final.h5")
                print(f"üì± TF Lite –º–æ–¥–µ–ª—å: {tflite_path}")
                if edge_tpu_path:
                    print(f"üß† Coral TPU –º–æ–¥–µ–ª—å: {edge_tpu_path}")
                print(f"üè∑Ô∏è  –§–∞–π–ª –º–µ—Ç–æ–∫: labels.txt")
                print("\nüöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É:")
                print("   python main_multicamera.py cameras.yaml")
            else:
                print("‚ö†Ô∏è  –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, –Ω–æ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
        else:
            print("‚ùå –û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å")

    except KeyboardInterrupt:
        print("\nüõë –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()